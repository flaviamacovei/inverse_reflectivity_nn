device: 'cpu' # accepted values: "auto", "cpu"

seed: null # <value> or null

num_stacks: 1

layers:
  min: 1 # must be >= 1
  max: &max_layers 20

wavelengths:
  start: 300.e-3
  end: 1499.e-3
  steps: 1200

polarisation: 's' # accepted values: "s", "p"

thicknesses_bounds:
  min: 1.e-9
  max: 1.e-6

materials:
  substrate: "DC_Substrate" # accepted values: "Suprasil Heraeus", "Suprasil", "BK7", "DC_Substrate"
  air: "DC_Air" # accepted values: "Air", "DC_Air"
  thin_films:
#    - "SiO2 IBS"
#    - "TiO2 IBS"
    - "H"
    - "L"
    - "A"
    - "F"
    - "M"
    - "T"
    - "Ag"
    - "Au"
    - "Ni"

theta:
  start: 0.
  end: 0.
  steps: 1

num_layers: *max_layers

material_embedding:
  data_file: "data/material_embedding/materials.yaml"
  dim: 2
  num_epochs: 200
  guided_learning_rate: 0.01
  free_learning_rate: 1.e-5

tolerance: 1.0e-3

architecture: &architecture "transformer" # accepted values: "gradient", "mlp", "cnn", "transformer"

transformer:
  model_dim: 256 # 256 or maybe even 1024
  num_heads: 8 # 8
  num_layers: 6 # 6
  d_ff: 1024 # 1024
  dropout: 0.1

training:
  guided_learning_rate: &glr 0.001 # default: 0.001
  free_learning_rate: &flr 1.e-4
  num_epochs: &epochs 500
  batch_size: &batch_size 256
  dataset_size: 5000
  save_model: true
  evaluate: true
  guidance_schedule:
  # for each leg specify: guidance in {"guided", "free"}, density in {"complete", "masked", "explicit"}, percent in {0 ... 1}
  # percent is the percentage of the epochs that will be spent training on the given density and guidance
  # note that the combination "guided-explicit" is not allowed
    - guidance: "guided"
      density: "complete"
      percent: 0.2
    - guidance: "guided"
      density: "masked"
      percent: 0.2
    - guidance: "free"
      density: "complete"
      percent: 0.2
    - guidance: "free"
      density: "masked"
      percent: 0.2
    - guidance: "free"
      density: "explicit"
      percent: 0.2

wandb:
  log: true
  project: "inverse-mirrors-nn"
  config:
    architecture: *architecture
    guided_learning_rate: *glr
    free_learning_rate: *flr
    epochs: *epochs
    batch_size: *batch_size
