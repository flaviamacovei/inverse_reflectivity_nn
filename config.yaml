device: 'auto' # accepted values: "auto", "cpu"

seed: null # <value> or null

num_stacks: 1

layers:
  min: 1 # must be >= 1
  max: &max_layers 20

wavelengths:
  start: 300.e-3
  end: 1499.e-3
  steps: 1200

polarisation: 's' # accepted values: "s", "p"

thicknesses_bounds:
  min: 1.e-9
  max: 1.e-6

materials:
  substrate: "DC_Substrate" # accepted values: "Suprasil Heraeus", "Suprasil", "BK7", "DC_Substrate"
  air: "DC_Air" # accepted values: "Air", "DC_Air"
  thin_films:
#    - "SiO2 IBS"
#    - "TiO2 IBS"
    - "H"
    - "L"
    - "A"
    - "F"
    - "M"
    - "T"
    - "Ag"
    - "Au"
    - "Ni"

theta:
  start: 0.
  end: 0.
  steps: 1

num_layers: *max_layers

material_embedding:
  data_file: "data/material_embedding/materials.yaml"
  # use pca
  # for constantrimaterials: embedding = ri
  dim: 2
  num_epochs: 200
  learning_rate: 0.01

tolerance: 1.0e-3

architecture: &architecture "transformer" # accepted values: "gradient", "mlp", "cnn", "transformer"

transformer:
  model_dim: 16 # 256 or maybe even 1024
  num_heads: 4 # 8
  num_layers: 5 # 6
  d_ff: 1024 # 1024
  dropout: 0.1

# possibly: different optimiser (numpy linesearch without parameters)

training:
  guided_learning_rate: &glr 0.0001 # default: 0.001
  free_learning_rate: &flr 1.e-5
  num_epochs: &epochs 500
  batch_size: &batch_size 64 # should be <= size of dataset
  dataset_size: 5000
  save_model: true
  evaluate: true
  guidance_schedule:
  # for each leg specify: guidance in {"guided", "free"}, density in {"complete", "masked", "explicit"}, percent in {0 ... 1}
  # percent is the percentage of the epochs that will be spent training on the given density and guidance
  # note that the combination "guided-explicit" is not allowed
    - guidance: "guided"
      density: "complete"
      percent: 0.2
    - guidance: "guided"
      density: "masked"
      percent: 0.2
    - guidance: "free"
      density: "complete"
      percent: 0.2
    - guidance: "free"
      density: "masked"
      percent: 0.2
    - guidance: "free"
      density: "explicit"
      percent: 0.2

wandb:
  log: true
  project: "inverse-mirrors-nn"
  config:
    architecture: *architecture
    guided_learning_rate: *glr
    free_learning_rate: *flr
    epochs: *epochs
    batch_size: *batch_size
